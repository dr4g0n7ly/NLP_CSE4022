{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYgVpWOk5YdI"
      },
      "outputs": [],
      "source": [
        "!pip install -Uqq datasets\n",
        "!pip install -Uqq transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRb2mkMHVvWv"
      },
      "source": [
        "## Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVbOb3iE5mLd",
        "outputId": "659df525-e8d9-405e-ae90-787a3b721bd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text', 'feeling'],\n",
            "        num_rows: 119988\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['text', 'feeling'],\n",
            "        num_rows: 29997\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text', 'feeling'],\n",
            "        num_rows: 61998\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"carblacac/twitter-sentiment-analysis\")\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaTVNQoyV5sL"
      },
      "source": [
        "## Split dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_7MgEkhV8k9",
        "outputId": "d7af743f-c815-4c4a-c22b-d1879ca85033"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample: {'text': \"@bradleyjp decidedly undecided. Depends on the situation. When I'm out with the people I'll be in Chicago with? Maybe.\", 'feeling': 1}\n"
          ]
        }
      ],
      "source": [
        "train_data = dataset[\"train\"]\n",
        "val_data = dataset[\"validation\"]\n",
        "test_data = dataset[\"test\"]\n",
        "\n",
        "# sample data point\n",
        "sample = train_data[2]\n",
        "print(\"Sample:\", sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxZCNstJoZ45"
      },
      "outputs": [],
      "source": [
        "x_train = [item['text'] for item in train_data]\n",
        "y_train = [item['feeling'] for item in train_data]\n",
        "\n",
        "x_val = [item['text'] for item in val_data]\n",
        "y_val = [item['feeling'] for item in val_data]\n",
        "\n",
        "x_test = [item['text'] for item in test_data]\n",
        "y_test = [item['feeling'] for item in test_data]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSS6zUBgnMl3"
      },
      "source": [
        "## Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBV600QSlhrm",
        "outputId": "cefe453c-1e27-4555-c440-4e9de190fabc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is example sentence \n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def preprocess_string(s):\n",
        "    s = re.sub(r\"[^\\w\\s]\", '', s)\n",
        "    s = re.sub(r\"\\s+\", ' ', s)\n",
        "    s = re.sub(r\"\\d\", '', s)\n",
        "    s = re.sub(r\" {2,}\", ' ', s)\n",
        "    return s\n",
        "\n",
        "# Example\n",
        "text = \"This is 500  example sentence.\\n\"\n",
        "prs_text = preprocess_string(text)\n",
        "print(prs_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXaEBHDr3SOH"
      },
      "source": [
        "## Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tN1Zpi0u0-HE",
        "outputId": "c1636ca1-d8b0-4f2e-b29c-4342fcde1dea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['This', 'is', 'example', 'sentence', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "def tokenize(text, max_length):\n",
        "    pre_text = preprocess_string(text)\n",
        "    doc = nlp(pre_text)\n",
        "    tokens = [token.text for token in doc]\n",
        "    padded_tokens = tokens + ['<PAD>'] * (max_length - len(tokens))\n",
        "    return padded_tokens[:max_length]\n",
        "\n",
        "# Example\n",
        "text = \"This is 500  example sentence.\\n\"\n",
        "tokens = tokenize(text, 10)\n",
        "print(tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vrGzvL32VNY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CpI5Tqy60OiX",
        "outputId": "83eb22e5-643c-491a-d9d1-69b6e48541a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['faami', 'so', 'happy', 'that', 'salman', 'won', 'btw', 'the', 'sec', 'clip', 'is', 'truely', 'a', 'teaser', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
          ]
        }
      ],
      "source": [
        "max_length = 20\n",
        "\n",
        "# Tokenize and pad\n",
        "x_train_tokenized = [tokenize(text, max_length) for text in x_train]\n",
        "x_val_tokenized = [tokenize(text, max_length) for text in x_val]\n",
        "x_test_tokenized = [tokenize(text, max_length) for text in x_test]\n",
        "\n",
        "print(x_train_tokenized[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tQtQY0mL9bl2"
      },
      "outputs": [],
      "source": [
        "all_tokenized_sentences = x_train_tokenized + x_val_tokenized + x_test_tokenized\n",
        "vocab = set(word for sentence in all_tokenized_sentences for word in sentence)\n",
        "word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
        "\n",
        "x_train_indices = [[word_to_idx[word] for word in sentence] for sentence in x_train_tokenized]\n",
        "x_val_indices = [[word_to_idx[word] for word in sentence] for sentence in x_val_tokenized]\n",
        "x_test_indices = [[word_to_idx[word] for word in sentence] for sentence in x_test_tokenized]\n",
        "\n",
        "# PyTorch tensors\n",
        "x_train_tensor = torch.tensor(x_train_indices)\n",
        "y_train_tensor = torch.tensor(y_train)\n",
        "\n",
        "x_val_tensor = torch.tensor(x_val_indices)\n",
        "y_val_tensor = torch.tensor(y_val)\n",
        "\n",
        "x_test_tensor = torch.tensor(x_test_indices)\n",
        "y_test_tensor = torch.tensor(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yh9y5P5XBltQ",
        "outputId": "7bc93ec4-0ce2-4a34-ed70-d027b2297367"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train shape:  torch.Size([119988, 20])\n",
            "y_train shape:  torch.Size([119988])\n"
          ]
        }
      ],
      "source": [
        "x_train_tensor = x_train_tensor.to(torch.float32)\n",
        "y_train_tensor = y_train_tensor.to(torch.float32)\n",
        "\n",
        "x_val_tensor = x_val_tensor.to(torch.float32)\n",
        "y_val_tensor = y_val_tensor.to(torch.float32)\n",
        "\n",
        "x_test_tensor = x_test_tensor.to(torch.float32)\n",
        "y_test_tensor = y_test_tensor.to(torch.float32)\n",
        "\n",
        "print(\"x_train shape: \", x_train_tensor.shape)\n",
        "print(\"y_train shape: \", y_train_tensor.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model definition and instantiation"
      ],
      "metadata": {
        "id": "9qlX5KanTL0b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jWnkCNl0K4JU"
      },
      "outputs": [],
      "source": [
        "class BiLSTMModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(BiLSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, bidirectional=True, num_layers=2)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, _ = self.lstm(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FOfn4A1ENPLM"
      },
      "outputs": [],
      "source": [
        "input_dim = 20\n",
        "hidden_dim = 64\n",
        "output_dim = 1\n",
        "\n",
        "model = BiLSTMModel(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "je7n1W3LTI80"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ep7scU66QiWq",
        "outputId": "7ca49a5f-a3e3-4c52-e44c-1bfa5412e4f7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0, Iteration: 0, Loss: 0.00027785994461737573\n",
            "Epoch: 0, Iteration: 20000, Loss: 0.25416967272758484\n",
            "Epoch: 0, Iteration: 40000, Loss: 0.22865530848503113\n",
            "Epoch: 0, Iteration: 60000, Loss: 0.2692406177520752\n",
            "Epoch: 0, Iteration: 80000, Loss: 0.26451122760772705\n",
            "Epoch: 0, Iteration: 100000, Loss: 0.24509358406066895\n",
            "Epoch: 1, Iteration: 0, Loss: 0.2372581660747528\n",
            "Epoch: 1, Iteration: 20000, Loss: 0.2535167336463928\n",
            "Epoch: 1, Iteration: 40000, Loss: 0.2395762801170349\n",
            "Epoch: 1, Iteration: 60000, Loss: 0.2693035304546356\n",
            "Epoch: 1, Iteration: 80000, Loss: 0.2642890214920044\n",
            "Epoch: 1, Iteration: 100000, Loss: 0.24509380757808685\n",
            "Epoch: 2, Iteration: 0, Loss: 0.23725979030132294\n",
            "Epoch: 2, Iteration: 20000, Loss: 0.2535351514816284\n",
            "Epoch: 2, Iteration: 40000, Loss: 0.2388027310371399\n",
            "Epoch: 2, Iteration: 60000, Loss: 0.26929134130477905\n",
            "Epoch: 2, Iteration: 80000, Loss: 0.26429951190948486\n",
            "Epoch: 2, Iteration: 100000, Loss: 0.24503910541534424\n",
            "Epoch: 3, Iteration: 0, Loss: 0.2372926026582718\n",
            "Epoch: 3, Iteration: 20000, Loss: 0.2534727454185486\n",
            "Epoch: 3, Iteration: 40000, Loss: 0.23840218782424927\n",
            "Epoch: 3, Iteration: 60000, Loss: 0.2693662643432617\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(5):\n",
        "    for i in range(len(x_train_tensor)):\n",
        "\n",
        "        x = x_train_tensor[i].unsqueeze(0)\n",
        "        y = y_train_tensor[i]\n",
        "\n",
        "        outputs = model(x)\n",
        "        loss = criterion(outputs, y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if i % 20000 == 0:\n",
        "            print('Epoch: {}, Iteration: {}, Loss: {}'.format(epoch, i, loss.item()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaulation"
      ],
      "metadata": {
        "id": "8okSdK14TFZT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "X77DWNkVQwK0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "804b0178-da47-4ef6-8f72-57d93d633454"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 73.3453\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    outputs = model(x_test_tensor)\n",
        "    predictions = outputs.round()\n",
        "    accuracy = (predictions == y_test_tensor).float().mean()\n",
        "    print('Accuracy:', accuracy.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5eqDttvRU8Q"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}